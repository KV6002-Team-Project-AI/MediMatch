{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77bc4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: torch in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers[torch]) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers[torch]) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.65.0)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.2.0)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.28.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from accelerate) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from accelerate) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from accelerate) (0.3.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2023.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\abdullah\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Pip installs\n",
    "!pip install transformers torch\n",
    "!pip install transformers[torch]\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "052129f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"O\": 0, \"B-CONDITION\": 1, \"I-CONDITION\": 2, \"B-MEDICATION\": 3, \"I-MEDICATION\": 4}\n",
    "id2label = {0: \"O\", 1: \"B-CONDITION\", 2: \"I-CONDITION\", 3: \"B-MEDICATION\", 4: \"I-MEDICATION\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1662f198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdullah\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "c:\\Users\\Abdullah\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import os\n",
    "\n",
    "# Setting path\n",
    "base_path = \"D:/Abdullah/Documents/MediMatch\"\n",
    "model_relative_path = os.path.join(\"Abdul/NLP_Models/Medical\")\n",
    "model_path = os.path.join(base_path, model_relative_path)\n",
    "\n",
    "# Load model and tokenizers\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0121157f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDICATION: Escitalopram\n",
      "CONDITION: anxiety\n"
     ]
    }
   ],
   "source": [
    "# Example text here\n",
    "text = \"Using Escitalopram for anxiety management\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = outputs.logits\n",
    "predictions = logits.argmax(-1).squeeze().tolist()\n",
    "\n",
    "predicted_labels = [id2label[label] for label in predictions]\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
    "labeled_tokens = list(zip(tokens, predicted_labels))\n",
    "\n",
    "def aggregate_entities(tokens, predicted_labels):\n",
    "    entities = []\n",
    "    current_entity = []\n",
    "    current_label = None\n",
    "\n",
    "    for token, label in zip(tokens, predicted_labels):\n",
    "        # Skip over the special tokens\n",
    "        if token in [\"[CLS]\", \"[SEP]\"]:\n",
    "            continue\n",
    "\n",
    "        # Subword tokens\n",
    "        if token.startswith(\"##\"):\n",
    "            if current_entity:\n",
    "                current_entity[-1] += token[2:]  # Merge with the previous\n",
    "            continue\n",
    "\n",
    "        # BIO tags\n",
    "        if label.startswith(\"B-\"):\n",
    "            if current_entity:  # Save the previous \n",
    "                entities.append((current_label, \" \".join(current_entity)))\n",
    "            current_entity = [token]\n",
    "            current_label = label[2:]  # Remove the BIO prefix\n",
    "        elif label.startswith(\"I-\") and current_label == label[2:]:\n",
    "            current_entity.append(token)\n",
    "        else:  # O or different entity\n",
    "            if current_entity:  # Save the previous \n",
    "                entities.append((current_label, \" \".join(current_entity)))\n",
    "                current_entity = []\n",
    "                current_label = None\n",
    "\n",
    "    if current_entity:\n",
    "        entities.append((current_label, \" \".join(current_entity)))\n",
    "\n",
    "    return entities\n",
    "\n",
    "entities = aggregate_entities(tokens, predicted_labels)\n",
    "\n",
    "def filter_entities(entities, filter_words):\n",
    "    filtered_entities = []\n",
    "    for label, entity in entities:\n",
    "        filtered_entity_words = [word for word in entity.split() if word.lower() not in filter_words]\n",
    "        if filtered_entity_words: \n",
    "            filtered_entities.append((label, \" \".join(filtered_entity_words)))\n",
    "    return filtered_entities\n",
    "\n",
    "filter_words = {\"on\", \"for\", \"currently\", \"taking\"}\n",
    "filtered_entities = filter_entities(entities, filter_words)\n",
    "\n",
    "# Print Outptu\n",
    "for label, entity in filtered_entities:\n",
    "    print(f\"{label}: {entity}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDICATION: Zyrtec\n",
      "CONDITION: insomnia\n",
      "MEDICATION: Escitalopram\n",
      "CONDITION: for anxiety\n",
      "CONDITION: with osteoarthritis\n",
      "MEDICATION: on Haldol\n",
      "CONDITION: with fibromyalgia\n",
      "MEDICATION: on Lisinopril\n",
      "MEDICATION: taking Effexor\n",
      "CONDITION: insomnia\n",
      "CONDITION: with endometriosis\n",
      "CONDITION: migraines\n",
      "CONDITION: with ulcerative colitis\n",
      "MEDICATION: Using Lexapro\n",
      "CONDITION: seizures\n",
      "CONDITION: migraines\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "def process_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = logits.argmax(-1).squeeze().tolist()\n",
    "    predicted_labels = [id2label[label] for label in predictions]\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
    "    labeled_tokens = list(zip(tokens, predicted_labels))\n",
    "\n",
    "    def aggregate_entities(tokens, predicted_labels):\n",
    "        entities = []\n",
    "        current_entity = []\n",
    "        current_label = None\n",
    "        for token, label in zip(tokens, predicted_labels):\n",
    "            if token in [\"[CLS]\", \"[SEP]\"]:\n",
    "                continue\n",
    "            if token.startswith(\"##\"):\n",
    "                if current_entity:\n",
    "                    current_entity[-1] += token[2:]\n",
    "                continue\n",
    "            if label.startswith(\"B-\"):\n",
    "                if current_entity:\n",
    "                    entities.append((current_label, \" \".join(current_entity)))\n",
    "                current_entity = [token]\n",
    "                current_label = label[2:]\n",
    "            elif label.startswith(\"I-\") and current_label == label[2:]:\n",
    "                current_entity.append(token)\n",
    "            else:\n",
    "                if current_entity:\n",
    "                    entities.append((current_label, \" \".join(current_entity)))\n",
    "                    current_entity = []\n",
    "                    current_label = None\n",
    "        if current_entity:\n",
    "            entities.append((current_label, \" \".join(current_entity)))\n",
    "        return entities\n",
    "\n",
    "    entities = aggregate_entities(tokens, predicted_labels)\n",
    "\n",
    "    def filter_entities(entities, filter_words):\n",
    "        filtered_entities = []\n",
    "        for label, entity in entities:\n",
    "            filtered_entity_words = [word for word in entity.split() if word.lower() not in filter_words]\n",
    "            if filtered_entity_words:\n",
    "                filtered_entities.append((label, \" \".join(filtered_entity_words)))\n",
    "        return filtered_entities\n",
    "\n",
    "    filter_words = {\"of\", \"from\", \"to\", \"and\"}\n",
    "    filtered_entities = filter_entities(entities, filter_words)\n",
    "    return filtered_entities\n",
    "\n",
    "# Test data geneerated from CHATGPT\n",
    "test_data = [\n",
    "    \"Prescribed Zyrtec for migraines.\"\n",
    "    \"Suffering from insomnia.\"\n",
    "    \"Using Escitalopram for anxiety management\"\n",
    "    \"Diagnosed with osteoarthritis.\"\n",
    "    \"Mother is on Haldol for schizophrenia.\"\n",
    "    \"Diagnosed with fibromyalgia.\"\n",
    "    \"Currently on Lisinopril for hypertension.\"\n",
    "    \"Currently taking Effexor for migraines.\"\n",
    "    \"Experiencing insomnia.\"\n",
    "    \"Using Ibuprofen for anxiety.\"\n",
    "    \"Diagnosed with endometriosis.\"\n",
    "    \"Taking Lorazepam for anxiety.\"\n",
    "    \"Suffering from migraines.\"\n",
    "    \"Diagnosed with ulcerative colitis.\"\n",
    "    \"Using Lexapro.\"\n",
    "    \"Suffering from seizures.\"\n",
    "    \"Suffering from migraines.\"\n",
    "    \"Using Haldol.\"\n",
    "    \n",
    "]\n",
    "\n",
    "# # Processing each phrase\n",
    "for text in test_data:\n",
    "    filtered_entities = process_text(text)\n",
    "    for label, entity in filtered_entities:\n",
    "        print(f\"{label}: {entity}\")\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b572981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n"
     ]
    }
   ],
   "source": [
    "def process_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = logits.argmax(-1).squeeze().tolist()\n",
    "    predicted_labels = [id2label[label] for label in predictions]\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
    "    labeled_tokens = list(zip(tokens, predicted_labels))\n",
    "\n",
    "    def aggregate_entities(tokens, predicted_labels):\n",
    "        entities = []\n",
    "        current_entity = []\n",
    "        current_label = None\n",
    "        for token, label in zip(tokens, predicted_labels):\n",
    "            if token in [\"[CLS]\", \"[SEP]\"]:\n",
    "                continue\n",
    "            if token.startswith(\"##\"):\n",
    "                if current_entity:\n",
    "                    current_entity[-1] += token[2:]\n",
    "                continue\n",
    "            if label.startswith(\"B-\"):\n",
    "                if current_entity:\n",
    "                    entities.append((current_label, \" \".join(current_entity)))\n",
    "                current_entity = [token]\n",
    "                current_label = label[2:]\n",
    "            elif label.startswith(\"I-\") and current_label == label[2:]:\n",
    "                current_entity.append(token)\n",
    "            else:\n",
    "                if current_entity:\n",
    "                    entities.append((current_label, \" \".join(current_entity)))\n",
    "                    current_entity = []\n",
    "                    current_label = None\n",
    "        if current_entity:\n",
    "            entities.append((current_label, \" \".join(current_entity)))\n",
    "        return entities\n",
    "\n",
    "    entities = aggregate_entities(tokens, predicted_labels)\n",
    "\n",
    "    def filter_entities(entities, filter_words):\n",
    "        filtered_entities = []\n",
    "        for label, entity in entities:\n",
    "            filtered_entity_words = [word for word in entity.split() if word.lower() not in filter_words]\n",
    "            if filtered_entity_words:\n",
    "                filtered_entities.append((label, \" \".join(filtered_entity_words)))\n",
    "        return filtered_entities\n",
    "\n",
    "    filter_words = {\"of\", \"from\", \"to\", \"and\"}\n",
    "    filtered_entities = filter_entities(entities, filter_words)\n",
    "    return filtered_entities\n",
    "\n",
    "# Test data geneerated from CHATGPT\n",
    "test_data = [\n",
    "\"I find joy in cooking healthy meals with fresh ingredients.\"\n",
    "\"I prioritize regular physical activity to maintain my fitness levels.\"\n",
    "\"I make time for hobbies that bring me joy and reduce stress.\"\n",
    "\"I prioritize self-care activities like baths and massages for relaxation.\"\n",
    "\"I enjoy family picnics as a way to bond and enjoy nutritious meals together.\"\n",
    "\"I prioritize sleep hygiene practices for better sleep and overall health.\"\n",
    "\"I make time for laughter and humor to improve my mood and well-being.\"\n",
    "\"I prioritize healthy snacks like fruits and nuts for sustained energy.\"\n",
    "\"I find joy in spending time with pets for my mental and emotional health.\"\n",
    "\"I enjoy swimming as a refreshing and low-impact form of exercise.\"\n",
    "\"I prioritize relaxation techniques like meditation for stress relief.\"\n",
    "\"I make time for regular family walks to catch up and connect.\"\n",
    "\"I prioritize regular check-ups to monitor my health and well-being.\"\n",
    "\"I find joy in exploring nature through activities like birdwatching.\"\n",
    "\"I prioritize spending time in nature to recharge and rejuvenate.\"\n",
    "\"I enjoy dancing to my favorite music as a form of exercise and self-expression.\"\n",
    "\"I prioritize spending time with loved ones to maintain strong relationships.\"\n",
    "\"I make time for hobbies like painting or crafting to relax and unwind.\"\n",
    "\"I enjoy cooking healthy meals as a way to nourish my body and soul.\"\n",
    "\"I prioritize time for relaxation and self-care to reduce stress levels.\"\n",
    "\"I practice mindfulness and meditation to stay grounded and focused.\"\n",
    "\"I prioritize getting enough sleep to ensure I have the energy for the day.\"\n",
    "\"I enjoy reading books to expand my knowledge and escape into different worlds.\"\n",
    "\"I volunteer at local charities to give back to the community and help those in need.\"\n",
    "\"I engage in regular physical activity to maintain my overall health and well-being.\"\n",
    "]\n",
    "\n",
    "# Processing each phrase\n",
    "for text in test_data:\n",
    "    filtered_entities = process_text(text)\n",
    "    for label, entity in filtered_entities:\n",
    "        print(f\"{label}: {entity}\")\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4432d01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n",
      "Precision: 0.76\n",
      "Recall: 1.00\n",
      "Specificity: 0.81\n",
      "F1 Score: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Values\n",
    "Total = 50\n",
    "True_Positives = 19\n",
    "False_Positives = 6\n",
    "total_empty = 25\n",
    "True_Negatives = 25\n",
    "False_Negatives = 0\n",
    "\n",
    "# Calculate \n",
    "accuracy = (True_Positives + True_Negatives) / Total\n",
    "precision = True_Positives / (True_Positives + False_Positives)\n",
    "recall = True_Positives / (True_Positives + False_Negatives)\n",
    "specificity = True_Negatives / (True_Negatives + False_Positives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")\n",
    "print(f\"F1 Score: {f1_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331350b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACROSS ALL 3 MODELS:\n",
    "# Average Accuracy: 0.91\n",
    "# Average Precision: 0.8033\n",
    "# Average Recall: 0.9733\n",
    "# Average Specificity: 0.7733\n",
    "# Average F1 Score: 0.88"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
